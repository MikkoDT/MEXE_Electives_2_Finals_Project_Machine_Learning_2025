{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf27\ufe0f Flood Prediction (NCR, Philippines) \u2014 Simple Machine Learning Notebook\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**Topic:** Flood Prediction using Rainfall, Water Level, and Elevation  \n",
        "**Model:** Logistic Regression (Binary Classification)  \n",
        "**Platform:** Google Colab  \n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udccc Quick Background (student write-up)\n",
        "Flooding is a common concern in some areas of NCR, especially during heavy rainfall.  \n",
        "In this activity, the proponents created a simple machine learning model that predicts if flooding will occur (**FloodOccurrence**) based on:\n",
        "\n",
        "- **Rainfall_mm** (mm)  \n",
        "- **WaterLevel_m** (m)  \n",
        "- **Elevation_m** (m)\n",
        "\n",
        "**Output**\n",
        "- `0` = No Flood  \n",
        "- `1` = Flood  \n",
        "\n",
        "> Note: The dataset typically has **more \u201cNo Flood\u201d** than \u201cFlood\u201d, so the notebook uses a basic imbalance handling technique.\n",
        "\n",
        "---\n",
        "\n",
        "## \u2705 What this notebook covers (based on the given instructions)\n",
        "A. Dataset Loading  \n",
        "B. Preprocessing (missing values, scaling, train/test split)  \n",
        "C. Logistic Regression Training  \n",
        "D. Model Evaluation (Accuracy, Confusion Matrix, Precision/Recall/F1, ROC)  \n",
        "E. Insights + Suggestions  \n",
        "F. A simple function to predict from new inputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) \u2699\ufe0f Imports\n",
        "This section imports the libraries used for data handling, training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_curve, auc\n",
        ")\n",
        "\n",
        "RANDOM_STATE = 123\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) \ud83d\udcc2 Dataset Loading (Colab)\n",
        "\n",
        "### How the proponents load the dataset:\n",
        "1. Upload the cleaned dataset (`cleaned_data.csv`) into Colab.\n",
        "2. Read the file using `pandas`.\n",
        "\n",
        "\u2705 **Tip:** If the dataset name is different, just edit `CSV_PATH`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Upload dataset file here (recommended in Google Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    print(\"Uploaded:\", list(uploaded.keys()))\n",
        "except Exception as e:\n",
        "    print(\"Upload skipped or not running in Colab.\")\n",
        "    print(\"Info:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Set the dataset filename here (default = cleaned_data.csv)\n",
        "CSV_PATH = \"cleaned_data.csv\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) \ud83d\udd0d Quick Dataset Check\n",
        "\n",
        "The proponents checked the following:\n",
        "- dataset size\n",
        "- column names\n",
        "- missing values\n",
        "- target distribution (to see if there is imbalance)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "\n",
        "print(\"\\nMissing values per column:\")\n",
        "display(df.isna().sum())\n",
        "\n",
        "if \"FloodOccurrence\" in df.columns:\n",
        "    print(\"\\nFloodOccurrence counts:\")\n",
        "    display(df[\"FloodOccurrence\"].value_counts())\n",
        "\n",
        "    print(\"\\nFloodOccurrence ratio:\")\n",
        "    display(df[\"FloodOccurrence\"].value_counts(normalize=True))\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f FloodOccurrence column was not found. Please check the dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) \ud83e\uddfc Preprocessing\n",
        "\n",
        "Based on the task instructions, preprocessing should include:\n",
        "\n",
        "\u2705 **Handle missing values**  \n",
        "\u2705 **Feature scaling** (StandardScaler recommended)  \n",
        "\u2705 **Train\u2013test split**\n",
        "\n",
        "### Why scaling?\n",
        "Rainfall values can be much larger (mm) compared to elevation and water level (meters).  \n",
        "Scaling helps Logistic Regression train more consistently.\n",
        "\n",
        "### Why imbalance handling?\n",
        "Flood events are often fewer than non-flood events.  \n",
        "So the proponents used:\n",
        "- `class_weight=\"balanced\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "FEATURES = [\"Rainfall_mm\", \"WaterLevel_m\", \"Elevation_m\"]\n",
        "TARGET = \"FloodOccurrence\"\n",
        "\n",
        "missing_cols = [c for c in FEATURES + [TARGET] if c not in df.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "X = df[FEATURES].copy()\n",
        "y = df[TARGET].copy()\n",
        "\n",
        "# Train-test split (required format from instructions)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape :\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Preprocessing + Model Pipeline\n",
        "\n",
        "To keep the workflow organized, the proponents used a pipeline:\n",
        "\n",
        "1. Median Imputation (for missing values)\n",
        "2. StandardScaler (feature scaling)\n",
        "3. Logistic Regression (classification model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) \ud83e\udd16 Model Training (Logistic Regression)\n",
        "\n",
        "In this step, the model learns from the training data to predict FloodOccurrence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "print(\"\u2705 Model training finished.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) \ud83d\udcca Model Evaluation\n",
        "\n",
        "For Logistic Regression, the required evaluation metrics are:\n",
        "\n",
        "- **Accuracy**\n",
        "- **Confusion Matrix**\n",
        "- **Precision, Recall, F1-score**\n",
        "- (Optional) ROC Curve\n",
        "\n",
        "> Since flood prediction is a safety-related case, the proponents focused more on **Recall** (catching flood cases).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Confusion Matrix\n",
        "\n",
        "- **TN**: correct No Flood\n",
        "- **FP**: false alarm (predicted flood but no flood)\n",
        "- **FN**: missed flood (most critical)\n",
        "- **TP**: correct Flood\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Flood (0)\", \"Flood (1)\"])\n",
        "disp.plot(values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix \u2014 Flood Prediction\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 ROC Curve (Optional)\n",
        "\n",
        "ROC curve helps visualize how well the model separates flood vs no-flood cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate (Recall)\")\n",
        "plt.title(\"ROC Curve \u2014 Flood Prediction\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) \ud83e\udde0 Insights (3\u20135)\n",
        "\n",
        "Below are sample insights written in a student-friendly way.  \n",
        "(Students can revise depending on their final metrics.)\n",
        "\n",
        "1. The dataset shows **class imbalance**, so `class_weight=\"balanced\"` was applied to help the model detect flood cases better.  \n",
        "2. Using **StandardScaler** improved training stability because features have different ranges and units.  \n",
        "3. **Recall** is important because missing a flood (false negative) can be more risky than a false alarm.  \n",
        "4. Rainfall and water level generally increase flood probability, while elevation may affect flood susceptibility.  \n",
        "5. The model can still be improved by adding more features (e.g., soil moisture, location, seasonal variables) and tuning the threshold.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Feature Influence (Optional Interpretation)\n",
        "\n",
        "This prints coefficients to see which features push the prediction toward flood (positive coefficient) or no flood (negative coefficient).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = pipeline.named_steps[\"model\"]\n",
        "coefs = model.coef_[0]\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": FEATURES,\n",
        "    \"Coefficient\": coefs,\n",
        "    \"Odds_Ratio (exp(coef))\": np.exp(coefs)\n",
        "}).sort_values(\"Coefficient\", ascending=False)\n",
        "\n",
        "display(coef_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) \ud83d\udd2e Predict Flood From New Inputs (Demo)\n",
        "\n",
        "This function is useful for the final presentation:\n",
        "- Input rainfall, water level, elevation\n",
        "- Output probability + predicted label\n",
        "\n",
        "The threshold can be adjusted:\n",
        "- Default: 0.50\n",
        "- Lower threshold: catches more floods (higher recall) but more false alarms\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def predict_flood(rainfall_mm: float, waterlevel_m: float, elevation_m: float, threshold: float = 0.50):\n",
        "    new_data = pd.DataFrame([{\n",
        "        \"Rainfall_mm\": rainfall_mm,\n",
        "        \"WaterLevel_m\": waterlevel_m,\n",
        "        \"Elevation_m\": elevation_m\n",
        "    }])\n",
        "\n",
        "    prob_flood = pipeline.predict_proba(new_data)[0][1]\n",
        "    pred = int(prob_flood >= threshold)\n",
        "\n",
        "    return {\n",
        "        \"Flood_Probability\": float(prob_flood),\n",
        "        \"Predicted_Class\": pred,\n",
        "        \"Meaning\": \"FLOOD\" if pred == 1 else \"NO FLOOD\",\n",
        "        \"Threshold_Used\": threshold\n",
        "    }\n",
        "\n",
        "# Sample demo values\n",
        "print(predict_flood(rainfall_mm=40, waterlevel_m=1.2, elevation_m=12))\n",
        "print(predict_flood(rainfall_mm=120, waterlevel_m=2.8, elevation_m=8))\n",
        "print(predict_flood(rainfall_mm=80, waterlevel_m=2.0, elevation_m=10, threshold=0.35))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---  \n",
        "## \u2705 End of Notebook\n",
        "\n",
        "**Submission reminder (GitHub structure):**\n",
        "- Notebook: `notebooks/`\n",
        "- Dataset: `data/`\n",
        "- README.md + requirements.txt in the main folder\n",
        "\n",
        "After running, the proponents should copy the final evaluation results (Accuracy, Recall, F1, AUC) into the README.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "name": "Flood_Prediction_StudentStyle_Colab.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}