# ğŸ©º Final Assessment â€” Machine Learning Model

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ 1. Pair Information

- **Pair Name:** Corona Chronicles
- **Members:**
  - Mendoza, Mark Jason  
  - Pangilinan, Von Mathew
- **Topic:** ğŸ©¸ Diabetes â€” Intermediate ğŸ—‚ï¸ Dataset
- **Chosen Model:** ğŸ“Š Logistic Regression

---

## ğŸ“Š 2. Dataset Overview

- **Dataset Source:**
  - ğŸ”— https://www.kaggle.com/datasets/samira1992/diabetes-intermediate-dataset/data

- **Description:**
    <p align="justify">
<strong>Diabetes Intermediate Dataset</strong> is a well-organized collection of health-related factors that include patient categories, diagnostic measures, and treatment results intended to support research and analysis of diabetes and its progression. The dataset contains a large number of features that can be used to examine the relationships between various medical parameters and the occurrence or management of diabetes in individuals.
</p>

- **Target Variable:**
  - ğŸ¯ **Outcome** (*`Non-Diabetic`* / *`Diabetic`*)

- **Features Used:**
  - ğŸ‘¶ *`Pregnancies`*
  - ğŸ¬ *`Glucose`*
  - ğŸ’“ *`BloodPressure`*
  - âœ‹ *`SkinThickness`*
  - ğŸ’‰ *`Insulin`*
  - âš–ï¸ *`BMI`*
  - ğŸ§¬ *`DiabetesPedigreeFunction`*
  - ğŸ‚ *`Age`*

---

## ğŸ§¹ Preprocessing Summary

<div style="text-align: justify">

- **Encoding**  
  â–¸ All features in the dataset are numerical; therefore, no categorical encoding was required. The target variable (`Outcome`) is already in binary numerical form and was used directly for model training.

- **Scaling**  
  â–¸ Standardization was applied to transform input features to zero mean and unit variance, ensuring equal contribution of variables and improving the stability of the Logistic Regression model.

- **Cleaning Steps**  
  â–¸ The dataset was checked for missing values and shuffled to eliminate potential ordering bias.  
  â–¸ The target variable was separated from the feature set to prepare the data for supervised learning.

- **Trainâ€“Test Split**  
  â–¸ The dataset was divided into training and testing sets, with 75% of the data used for training and 25% reserved for testing to evaluate performance on unseen data.

</div>

---

## ğŸ©º 4. Model & Results
- **Model Used:**  
  Logistic Regression 
- **Metrics:**  
  - âœ… Accuracy = `%`
  - ğŸ¯ Precision = `%`
  - ğŸ” Recall =  `%`
  - ğŸ§¾ F1-Score = `%`
  image ng Accuracy, Precision, Recall, at F1-Score
  
  - ğŸ©ºConfusion Matrix 
  <img width="401" height="351" alt="image" src="https://github.com/user-attachments/assets/bdd042d8-67fe-4f3c-b672-a78f0c55cde8" />

  -ğŸ“ˆ ROC Curve  
  <img width="567" height="455" alt="image" src="https://github.com/user-attachments/assets/674aaf48-5362-41f0-a15c-77b68a0fd311" />

- **Visualizations:**  
  - ğŸ”Scatterplot
  <img width="1489" height="1356" alt="image" src="https://github.com/user-attachments/assets/9d99e36c-54c3-4be4-bc81-4dcd17a6ed9f" />

  
  - ğŸ”¥Correlation Heatmap  
  <img width="914" height="691" alt="image" src="https://github.com/user-attachments/assets/44a9c60d-5b10-409d-b18b-d483a68e7f1a" />

  
- **Key Insights:**  
  - lagay dito
  
---

## âš™ï¸ 5. How to Run
1. Install VS Code + Python + Jupyter Extension
2. Install dependencies:

pip install -r requirements.txt

3. Open the `.ipynb` notebook
4. Run all cells
